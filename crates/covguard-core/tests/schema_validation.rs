//! JSON Schema validation tests for covguard reports.
//!
//! These tests ensure that:
//! 1. The JSON schemas themselves are valid
//! 2. Reports generated by covguard-app conform to the schema
//! 3. Invalid reports are rejected by schema validation

use covguard_core::{CheckRequest, Clock, check_with_clock};
use covguard_types::{Report, Scope};
use jsonschema::{Resource, Validator, draft202012};
use serde_json::{Value, json};
use std::path::PathBuf;

// ============================================================================
// Test Utilities
// ============================================================================

/// Get the workspace root directory.
fn workspace_root() -> PathBuf {
    // CARGO_MANIFEST_DIR is crates/covguard-app, go up two levels
    PathBuf::from(env!("CARGO_MANIFEST_DIR"))
        .parent()
        .expect("Failed to get crates/ directory")
        .parent()
        .expect("Failed to get workspace root")
        .to_path_buf()
}

/// Load the envelope schema JSON.
fn load_envelope_schema() -> Value {
    let path = workspace_root().join("contracts/schemas/receipt.envelope.v1.json");
    let content = std::fs::read_to_string(&path).unwrap_or_else(|e| {
        panic!(
            "Failed to read envelope schema at {}: {}",
            path.display(),
            e
        )
    });
    serde_json::from_str(&content).expect("Failed to parse envelope schema as JSON")
}

/// Load the report schema JSON.
fn load_report_schema() -> Value {
    let path = workspace_root().join("contracts/schemas/covguard.report.v1.json");
    let content = std::fs::read_to_string(&path)
        .unwrap_or_else(|e| panic!("Failed to read report schema at {}: {}", path.display(), e));
    serde_json::from_str(&content).expect("Failed to parse report schema as JSON")
}

/// Build a JSON Schema validator for covguard reports.
///
/// This handles the $ref resolution by modifying the report schema to use
/// the absolute URN reference instead of a relative path, then registering
/// the envelope schema as a resource.
fn build_validator() -> Validator {
    let envelope_json = load_envelope_schema();
    let mut report_json = load_report_schema();

    // The report schema references the envelope via:
    //   "$ref": "./receipt.envelope.v1.json"
    // Since URNs can't resolve relative paths, we modify the schema to use
    // the absolute URN reference: "urn:effortless:receipt.envelope.v1"
    if let Some(all_of) = report_json.get_mut("allOf")
        && let Some(arr) = all_of.as_array_mut()
        && let Some(first) = arr.get_mut(0)
        && let Some(obj) = first.as_object_mut()
        && obj.get("$ref") == Some(&json!("./receipt.envelope.v1.json"))
    {
        obj.insert(
            "$ref".to_string(),
            json!("urn:effortless:receipt.envelope.v1"),
        );
    }

    // Register the envelope schema by its $id so the $ref resolves
    draft202012::options()
        .with_resource(
            "urn:effortless:receipt.envelope.v1",
            Resource::from_contents(envelope_json),
        )
        .build(&report_json)
        .expect("Failed to compile report schema")
}

/// A test clock that returns a fixed time.
struct FixedClock {
    time: chrono::DateTime<chrono::Utc>,
}

impl FixedClock {
    fn new(timestamp: &str) -> Self {
        Self {
            time: chrono::DateTime::parse_from_rfc3339(timestamp)
                .unwrap()
                .with_timezone(&chrono::Utc),
        }
    }
}

impl Clock for FixedClock {
    fn now(&self) -> chrono::DateTime<chrono::Utc> {
        self.time
    }
}

/// Helper to validate a report and return detailed error info on failure.
fn validate_report(validator: &Validator, report: &Value) -> Result<(), String> {
    let result = validator.validate(report);
    match result {
        Ok(()) => Ok(()),
        Err(error) => Err(format!(
            "Schema validation failed at {}: {}",
            error.instance_path(),
            error
        )),
    }
}

// ============================================================================
// Schema Self-Validation Tests
// ============================================================================

#[test]
fn test_envelope_schema_is_valid_json() {
    let schema = load_envelope_schema();
    assert!(
        schema.is_object(),
        "Envelope schema should be a JSON object"
    );
    assert_eq!(
        schema["$schema"], "https://json-schema.org/draft/2020-12/schema",
        "Envelope schema should use draft 2020-12"
    );
    assert_eq!(
        schema["$id"], "urn:effortless:receipt.envelope.v1",
        "Envelope schema should have correct $id"
    );
}

#[test]
fn test_report_schema_is_valid_json() {
    let schema = load_report_schema();
    assert!(schema.is_object(), "Report schema should be a JSON object");
    assert_eq!(
        schema["$schema"], "https://json-schema.org/draft/2020-12/schema",
        "Report schema should use draft 2020-12"
    );
    assert_eq!(
        schema["$id"], "urn:effortless:covguard.report.v1",
        "Report schema should have correct $id"
    );
}

#[test]
fn test_schema_compiles() {
    // This will panic if the schema cannot be compiled
    let _validator = build_validator();
}

#[test]
fn test_envelope_schema_compiles_standalone() {
    let envelope_json = load_envelope_schema();
    let result = draft202012::options().build(&envelope_json);
    assert!(
        result.is_ok(),
        "Envelope schema should compile: {:?}",
        result.err()
    );
}

// ============================================================================
// Valid Report Validation Tests
// ============================================================================

#[test]
fn test_default_report_validates() {
    let validator = build_validator();
    let report = Report::default();
    let report_json = serde_json::to_value(&report).expect("Failed to serialize report");

    validate_report(&validator, &report_json)
        .expect("Default report should validate against schema");
}

#[test]
fn test_generated_report_validates_covered() {
    let diff = r#"diff --git a/src/lib.rs b/src/lib.rs
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/src/lib.rs
@@ -0,0 +1,3 @@
+pub fn add(a: i32, b: i32) -> i32 {
+    a + b
+}
"#;

    let lcov = r#"TN:
SF:src/lib.rs
DA:1,1
DA:2,1
DA:3,1
end_of_record
"#;

    let request = CheckRequest {
        diff_text: diff.to_string(),
        diff_file_path: Some("test.patch".to_string()),
        lcov_texts: vec![lcov.to_string()],
        lcov_paths: vec!["coverage.info".to_string()],
        threshold_pct: 80.0,
        scope: Scope::Added,
        ..Default::default()
    };

    let clock = FixedClock::new("2026-02-02T00:00:00Z");
    let result = check_with_clock(request, &clock).expect("Check should succeed");

    let validator = build_validator();
    let report_json = serde_json::to_value(&result.report).expect("Failed to serialize report");

    validate_report(&validator, &report_json)
        .expect("Generated covered report should validate against schema");
}

#[test]
fn test_generated_report_validates_uncovered() {
    let diff = r#"diff --git a/src/lib.rs b/src/lib.rs
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/src/lib.rs
@@ -0,0 +1,3 @@
+pub fn add(a: i32, b: i32) -> i32 {
+    a + b
+}
"#;

    let lcov = r#"TN:
SF:src/lib.rs
DA:1,0
DA:2,0
DA:3,0
end_of_record
"#;

    let request = CheckRequest {
        diff_text: diff.to_string(),
        diff_file_path: Some("test.patch".to_string()),
        lcov_texts: vec![lcov.to_string()],
        lcov_paths: vec!["coverage.info".to_string()],
        threshold_pct: 80.0,
        scope: Scope::Added,
        ..Default::default()
    };

    let clock = FixedClock::new("2026-02-02T00:00:00Z");
    let result = check_with_clock(request, &clock).expect("Check should succeed");

    let validator = build_validator();
    let report_json = serde_json::to_value(&result.report).expect("Failed to serialize report");

    validate_report(&validator, &report_json)
        .expect("Generated uncovered report should validate against schema");

    // Verify it has findings
    assert!(
        !result.report.findings.is_empty(),
        "Uncovered report should have findings"
    );
}

#[test]
fn test_golden_fixture_validates_covered() {
    let path = workspace_root().join("fixtures/expected/report_covered.json");
    let content = std::fs::read_to_string(&path)
        .unwrap_or_else(|e| panic!("Failed to read fixture at {}: {}", path.display(), e));
    let report_json: Value =
        serde_json::from_str(&content).expect("Failed to parse fixture as JSON");

    let validator = build_validator();
    validate_report(&validator, &report_json)
        .expect("Golden covered fixture should validate against schema");
}

#[test]
fn test_golden_fixture_validates_uncovered() {
    let path = workspace_root().join("fixtures/expected/report_uncovered.json");
    let content = std::fs::read_to_string(&path)
        .unwrap_or_else(|e| panic!("Failed to read fixture at {}: {}", path.display(), e));
    let report_json: Value =
        serde_json::from_str(&content).expect("Failed to parse fixture as JSON");

    let validator = build_validator();
    validate_report(&validator, &report_json)
        .expect("Golden uncovered fixture should validate against schema");
}

#[test]
fn test_golden_fixture_validates_partial() {
    let path = workspace_root().join("fixtures/expected/report_partial.json");
    let content = std::fs::read_to_string(&path)
        .unwrap_or_else(|e| panic!("Failed to read fixture at {}: {}", path.display(), e));
    let report_json: Value =
        serde_json::from_str(&content).expect("Failed to parse fixture as JSON");

    let validator = build_validator();
    validate_report(&validator, &report_json)
        .expect("Golden partial coverage fixture should validate against schema");
}

#[test]
fn test_report_with_git_refs_validates() {
    let diff = r#"diff --git a/src/lib.rs b/src/lib.rs
new file mode 100644
--- /dev/null
+++ b/src/lib.rs
@@ -0,0 +1,1 @@
+fn main() {}
"#;

    let lcov = r#"TN:
SF:src/lib.rs
DA:1,1
end_of_record
"#;

    let request = CheckRequest {
        diff_text: diff.to_string(),
        diff_file_path: None,
        base_ref: Some("main".to_string()),
        head_ref: Some("feature-branch".to_string()),
        lcov_texts: vec![lcov.to_string()],
        lcov_paths: vec!["coverage.info".to_string()],
        threshold_pct: 80.0,
        scope: Scope::Added,
        ..Default::default()
    };

    let clock = FixedClock::new("2026-02-02T00:00:00Z");
    let result = check_with_clock(request, &clock).expect("Check should succeed");

    let validator = build_validator();
    let report_json = serde_json::to_value(&result.report).expect("Failed to serialize report");

    validate_report(&validator, &report_json)
        .expect("Report with git refs should validate against schema");

    // Verify metadata
    assert_eq!(result.report.data.inputs.diff_source, "git-refs");
    assert_eq!(result.report.data.inputs.base, Some("main".to_string()));
    assert_eq!(
        result.report.data.inputs.head,
        Some("feature-branch".to_string())
    );
}

#[test]
fn test_report_with_empty_diff_validates() {
    let request = CheckRequest {
        diff_text: String::new(),
        lcov_texts: vec!["TN:\nSF:src/lib.rs\nDA:1,1\nend_of_record\n".to_string()],
        lcov_paths: vec!["coverage.info".to_string()],
        threshold_pct: 80.0,
        scope: Scope::Added,
        ..Default::default()
    };

    let clock = FixedClock::new("2026-02-02T00:00:00Z");
    let result = check_with_clock(request, &clock).expect("Check should succeed");

    let validator = build_validator();
    let report_json = serde_json::to_value(&result.report).expect("Failed to serialize report");

    validate_report(&validator, &report_json)
        .expect("Report with empty diff should validate against schema");
}

#[test]
fn test_report_touched_scope_validates() {
    let diff = r#"diff --git a/src/lib.rs b/src/lib.rs
new file mode 100644
--- /dev/null
+++ b/src/lib.rs
@@ -0,0 +1,1 @@
+fn main() {}
"#;

    let lcov = r#"TN:
SF:src/lib.rs
DA:1,1
end_of_record
"#;

    let request = CheckRequest {
        diff_text: diff.to_string(),
        diff_file_path: Some("test.patch".to_string()),
        lcov_texts: vec![lcov.to_string()],
        lcov_paths: vec!["coverage.info".to_string()],
        threshold_pct: 80.0,
        scope: Scope::Touched,
        ..Default::default()
    };

    let clock = FixedClock::new("2026-02-02T00:00:00Z");
    let result = check_with_clock(request, &clock).expect("Check should succeed");

    let validator = build_validator();
    let report_json = serde_json::to_value(&result.report).expect("Failed to serialize report");

    validate_report(&validator, &report_json)
        .expect("Report with touched scope should validate against schema");

    assert_eq!(result.report.data.scope, "touched");
}

// ============================================================================
// Invalid Report Tests (Negative Cases)
// ============================================================================

#[test]
fn test_invalid_missing_schema_field() {
    let validator = build_validator();
    let invalid_report = json!({
        // "schema" field is missing
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report missing 'schema' field should fail validation"
    );
}

#[test]
fn test_invalid_missing_tool_field() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        // "tool" field is missing
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report missing 'tool' field should fail validation"
    );
}

#[test]
fn test_invalid_missing_verdict_field() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        // "verdict" field is missing
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report missing 'verdict' field should fail validation"
    );
}

#[test]
fn test_invalid_missing_run_field() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        // "run" field is missing
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report missing 'run' field should fail validation"
    );
}

#[test]
fn test_invalid_missing_findings_field() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        // "findings" field is missing
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report missing 'findings' field should fail validation"
    );
}

#[test]
fn test_invalid_verdict_status_enum() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "invalid_status",  // Invalid enum value
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report with invalid verdict.status should fail validation"
    );
}

#[test]
fn test_invalid_severity_enum() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "fail",
            "counts": { "info": 0, "warn": 0, "error": 1 },
            "reasons": ["uncovered_lines"]
        },
        "findings": [
            {
                "severity": "critical",  // Invalid enum value (should be info/warn/error)
                "check_id": "diff.uncovered_line",
                "code": "covguard.diff.uncovered_line",
                "message": "Uncovered line"
            }
        ],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 1,
            "covered_lines": 0,
            "uncovered_lines": 1,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report with invalid severity should fail validation"
    );
}

#[test]
fn test_invalid_scope_enum() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "invalid_scope",  // Invalid enum value (should be added/touched)
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report with invalid data.scope should fail validation"
    );
}

#[test]
fn test_invalid_negative_count() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": -1, "warn": 0, "error": 0 },  // Negative count
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report with negative count should fail validation"
    );
}

#[test]
fn test_invalid_negative_changed_lines() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": -5,  // Negative value
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report with negative changed_lines_total should fail validation"
    );
}

#[test]
fn test_invalid_threshold_out_of_range() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 150.0,  // Out of range (max 100)
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report with threshold > 100 should fail validation"
    );
}

#[test]
fn test_invalid_coverage_pct_out_of_range() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": -10.0,  // Negative percentage
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report with negative diff_coverage_pct should fail validation"
    );
}

#[test]
fn test_invalid_line_number_zero() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "fail",
            "counts": { "info": 0, "warn": 0, "error": 1 },
            "reasons": ["uncovered_lines"]
        },
        "findings": [
            {
                "severity": "error",
                "check_id": "diff.uncovered_line",
                "code": "covguard.diff.uncovered_line",
                "message": "Uncovered line",
                "location": {
                    "path": "src/lib.rs",
                    "line": 0  // Invalid: minimum is 1
                }
            }
        ],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 1,
            "covered_lines": 0,
            "uncovered_lines": 1,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report with line number 0 should fail validation (minimum is 1)"
    );
}

#[test]
fn test_invalid_missing_tool_name() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            // "name" is missing (required)
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report missing tool.name should fail validation"
    );
}

#[test]
fn test_invalid_missing_verdict_counts() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            // "counts" is missing (required)
            "reasons": []
        },
        "findings": [],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report missing verdict.counts should fail validation"
    );
}

#[test]
fn test_invalid_missing_finding_code() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "fail",
            "counts": { "info": 0, "warn": 0, "error": 1 },
            "reasons": ["uncovered_lines"]
        },
        "findings": [
            {
                "severity": "error",
                // "code" is missing (required)
                "message": "Uncovered line"
            }
        ],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 1,
            "covered_lines": 0,
            "uncovered_lines": 1,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report with finding missing 'code' should fail validation"
    );
}

#[test]
fn test_invalid_wrong_type_for_findings() {
    let validator = build_validator();
    let invalid_report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 },
            "reasons": []
        },
        "findings": "not an array",  // Should be an array
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 0,
            "covered_lines": 0,
            "uncovered_lines": 0,
            "missing_lines": 0,
            "diff_coverage_pct": 0.0,
            "inputs": {
                "diff_source": "diff-file",
                "lcov_paths": []
            }
        }
    });

    let result = validate_report(&validator, &invalid_report);
    assert!(
        result.is_err(),
        "Report with findings as string should fail validation"
    );
}

// ============================================================================
// Edge Case Tests
// ============================================================================

#[test]
fn test_valid_report_with_all_optional_fields() {
    let validator = build_validator();
    let report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0",
            "commit": "abc123def456"  // Optional field
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z",
            "ended_at": "2026-02-02T00:00:01Z",  // Optional
            "duration_ms": 1000,  // Optional
            "host": {  // Optional
                "os": "linux",
                "arch": "x86_64",
                "ci": "github-actions"
            },
            "git": {  // Optional
                "base_ref": "main",
                "head_ref": "feature",
                "base_sha": "abc123",
                "head_sha": "def456",
                "merge_base": "abc123"
            }
        },
        "verdict": {
            "status": "fail",
            "counts": { "info": 1, "warn": 2, "error": 3 },
            "reasons": ["uncovered_lines", "below_threshold"]
        },
        "findings": [
            {
                "severity": "error",
                "check_id": "diff.uncovered_line",
                "code": "covguard.diff.uncovered_line",
                "message": "Uncovered changed line",
                "location": {
                    "path": "src/lib.rs",
                    "line": 42,
                    "col": 5  // Optional
                },
                "help": "Add a test for this line",  // Optional
                "url": "https://docs.example.com/coverage",  // Optional
                "fingerprint": "abc123",  // Optional
                "data": { "hits": 0 }  // Optional
            }
        ],
        "data": {
            "scope": "added",
            "threshold_pct": 80.0,
            "changed_lines_total": 10,
            "covered_lines": 5,
            "uncovered_lines": 3,
            "missing_lines": 2,
            "diff_coverage_pct": 50.0,
            "ignored_lines_count": 1,  // Optional
            "excluded_files_count": 2,  // Optional
            "inputs": {
                "diff_source": "git-refs",
                "diff_file": "test.patch",
                "base": "main",
                "head": "feature",
                "lcov_paths": ["coverage1.info", "coverage2.info"]
            },
            "truncation": {  // Optional
                "findings_truncated": true,
                "shown": 50,
                "total": 100
            },
            "debug": { "extra": "data" }  // Optional
        }
    });

    validate_report(&validator, &report).expect("Report with all optional fields should validate");
}

#[test]
fn test_valid_report_minimal() {
    let validator = build_validator();
    // Minimal valid report with only required fields
    let report = json!({
        "schema": "covguard.report.v1",
        "tool": {
            "name": "covguard",
            "version": "0.1.0"
        },
        "run": {
            "started_at": "2026-02-02T00:00:00Z"
        },
        "verdict": {
            "status": "pass",
            "counts": { "info": 0, "warn": 0, "error": 0 }
        },
        "findings": []
    });

    validate_report(&validator, &report).expect("Minimal valid report should validate");
}

// ============================================================================
// Dynamic Fixture Validation
// ============================================================================

/// Validates ALL JSON files in fixtures/expected/ against the schema.
/// This ensures any new fixtures added to the directory are automatically tested.
#[test]
fn test_all_golden_fixtures_validate() {
    let validator = build_validator();
    let fixtures_dir = workspace_root().join("fixtures/expected");

    let entries = std::fs::read_dir(&fixtures_dir).unwrap_or_else(|e| {
        panic!(
            "Failed to read fixtures directory at {}: {}",
            fixtures_dir.display(),
            e
        )
    });

    let mut tested_count = 0;
    for entry in entries {
        let entry = entry.expect("Failed to read directory entry");
        let path = entry.path();

        // Only test .json files
        if path.extension().and_then(|s| s.to_str()) != Some("json") {
            continue;
        }

        let content = std::fs::read_to_string(&path)
            .unwrap_or_else(|e| panic!("Failed to read fixture at {}: {}", path.display(), e));
        let report_json: Value = serde_json::from_str(&content)
            .unwrap_or_else(|e| panic!("Failed to parse {} as JSON: {}", path.display(), e));

        validate_report(&validator, &report_json).unwrap_or_else(|e| {
            panic!(
                "Golden fixture {} failed schema validation: {}",
                path.display(),
                e
            )
        });

        tested_count += 1;
    }

    assert!(
        tested_count >= 3,
        "Expected at least 3 golden fixtures, found {}",
        tested_count
    );
}
